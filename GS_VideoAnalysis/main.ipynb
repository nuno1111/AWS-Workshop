{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Upstage OCR 시작/중지 ( API / Batch )\n",
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = \"us-east-1\" # Bedrock과 Sagemaker Region은 us-east-1으로 설정\n",
    "\n",
    "boto3_session = boto3.Session(region_name=region_name)\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\",region_name=region_name)\n",
    "sagemaker_client = boto3.client('sagemaker',region_name=region_name)\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# role = get_execution_role()\n",
    "sagemaker_role = \"AmazonSageMaker-ExecutionRole-20240820T145192\"\n",
    "sagemaker_role_arn = \"arn:aws:iam::761482380245:role/service-role/AmazonSageMaker-ExecutionRole-20240820T145192\"\n",
    "s3_bucket = \"gsshop-video-analysis-761482380245-ap-northeast-2\"\n",
    "key = \"images/trigger/prd_01/vrid_00003/_SUCCUESS\"\n",
    "prefix = key.replace(\"_SUCCUESS\",\"\")\n",
    "\n",
    "endpoint_config_name = \"Upstage-Document-OCR-config\"\n",
    "endpoint_name = \"endpoint-Upstage-Document-OCR\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Package: 'arn:aws:sagemaker:us-east-1:865070037744:model-package/upstage-document-ocr-240704-r1-8b4651227fa23fc6925dedbc4b4d1437'\n"
     ]
    }
   ],
   "source": [
    "model_package_name = \"upstage-document-ocr-240704-r1-8b4651227fa23fc6925dedbc4b4d1437\"\n",
    "\n",
    "# Mapping for Model Packages\n",
    "model_package_map = {\n",
    "    \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:865070037744:model-package/{model_package_name}\",\n",
    "    \"us-east-2\": f\"arn:aws:sagemaker:us-east-2:057799348421:model-package/{model_package_name}\",\n",
    "    \"us-west-1\": f\"arn:aws:sagemaker:us-west-1:382657785993:model-package/{model_package_name}\",\n",
    "    \"us-west-2\": f\"arn:aws:sagemaker:us-east-1:594846645681:model-package/{model_package_name}\",\n",
    "    \"ca-central-1\": f\"arn:aws:sagemaker:ca-central-1:470592106596:model-package/{model_package_name}\",\n",
    "    \"eu-central-1\": f\"arn:aws:sagemaker:eu-central-1:446921602837:model-package/{model_package_name}\",\n",
    "    \"eu-west-1\": f\"arn:aws:sagemaker:eu-west-1:985815980388:model-package/{model_package_name}\",\n",
    "    \"eu-west-2\": f\"arn:aws:sagemaker:eu-west-2:856760150666:model-package/{model_package_name}\",\n",
    "    \"eu-west-3\": f\"arn:aws:sagemaker:eu-west-3:843114510376:model-package/{model_package_name}\",\n",
    "    \"eu-north-1\": f\"arn:aws:sagemaker:eu-north-1:136758871317:model-package/{model_package_name}\",\n",
    "    \"ap-southeast-1\": f\"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/{model_package_name}\",\n",
    "    \"ap-southeast-2\": f\"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/{model_package_name}\",\n",
    "    \"ap-northeast-2\": f\"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/{model_package_name}\",\n",
    "    \"ap-northeast-1\": f\"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/{model_package_name}\",\n",
    "    \"ap-south-1\": f\"arn:aws:sagemaker:ap-south-1:077584701553:model-package/{model_package_name}\",\n",
    "    \"sa-east-1\": f\"arn:aws:sagemaker:sa-east-1:270155090741:model-package/{model_package_name}\",\n",
    "}\n",
    "\n",
    "if region_name not in model_package_map.keys():\n",
    "    raise Exception(f\"Current boto3 session region {region_name} is not supported.\")\n",
    "\n",
    "model_package_arn = (\n",
    "    model_package_map[region_name]\n",
    ")\n",
    "\n",
    "print(f\"Model Package: '{model_package_arn}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Upstage-Document-OCR\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.g5.2xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 생성 성공. 모델 response: {'ModelArn': 'arn:aws:sagemaker:us-east-1:761482380245:model/Upstage-Document-OCR', 'ResponseMetadata': {'RequestId': 'e9ca129a-cfd2-4cb8-aa88-4276857f767c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e9ca129a-cfd2-4cb8-aa88-4276857f767c', 'content-type': 'application/x-amz-json-1.1', 'content-length': '82', 'date': 'Mon, 02 Sep 2024 04:35:35 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 2-1. 모델 생성 (최초 1회)\n",
    "response = sagemaker_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'ModelPackageName': model_package_arn\n",
    "    },\n",
    "    ExecutionRoleArn=sagemaker_role_arn,\n",
    "    EnableNetworkIsolation=True\n",
    ")\n",
    "print(f\"모델 생성 성공. 모델 response: {response}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참조 - 모델 생성 (최초 1회) CLI로 생성\n",
    "\n",
    "```bash\n",
    "export MODEL_NAME=Upstage-Document-OCR\n",
    "export MODEL_PACKAGE_ARN=arn:aws:sagemaker:us-east-1:865070037744:model-package/upstage-document-ocr-240704-r1-8b4651227fa23fc6925dedbc4b4d1437\n",
    "export SAGEMAKER_ROLE_ARN=arn:aws:iam::761482380245:role/service-role/AmazonSageMaker-ExecutionRole-20240820T145192\n",
    "\n",
    "aws sagemaker create-model \\\n",
    "    --model-name $MODEL_NAME \\\n",
    "    --primary-container '{\"ModelPackageName\": \"'$MODEL_PACKAGE_ARN'\"}' \\\n",
    "    --execution-role-arn $SAGEMAKER_ROLE_ARN \\\n",
    "    --enable-network-isolation\n",
    "\n",
    "echo \"모델 생성 성공.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint config name: 'Upstage-Document-OCR-config'\n",
      "Endpoint configuration 생성성공. response: {'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:761482380245:endpoint-config/Upstage-Document-OCR-config', 'ResponseMetadata': {'RequestId': '6058b6fd-cef0-4e71-8e0b-8ec0769626f9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6058b6fd-cef0-4e71-8e0b-8ec0769626f9', 'content-type': 'application/x-amz-json-1.1', 'content-length': '108', 'date': 'Mon, 02 Sep 2024 04:39:57 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 2-2. 모델 Endpoint Config 생성 (최초 1회 만 생성)\n",
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "print(f\"Endpoint config name: '{endpoint_config_name}'\")\n",
    "\n",
    "response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'ModelName': model_name,\n",
    "            'InstanceType': real_time_inference_instance_type,\n",
    "            'InitialInstanceCount': 1,\n",
    "            # 'InitialVariantWeight': 1.0\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(f\"Endpoint configuration 생성성공. response: {response}\")\n",
    "\n",
    "# 참조 - CLI로 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참조 - 2-2. 모델 Endpoint Config 생성 CLI로 생성\n",
    "\n",
    "```bash\n",
    "\n",
    "export ENDPOINT_CONFIG_NAME=Upstage-Document-OCR-config\n",
    "export MODEL_NAME=Upstage-Document-OCR\n",
    "export REAL_TIME_INFERENCE_INSTANCE_TYPE=ml.g5.2xlarge\n",
    "\n",
    "aws sagemaker create-endpoint-config \\\n",
    "    --endpoint-config-name $ENDPOINT_CONFIG_NAME \\\n",
    "    --production-variants '[{\n",
    "        \"VariantName\": \"AllTraffic\",\n",
    "        \"ModelName\": \"'$MODEL_NAME'\",\n",
    "        \"InstanceType\": \"'$REAL_TIME_INFERENCE_INSTANCE_TYPE'\",\n",
    "        \"InitialInstanceCount\": 1\n",
    "    }]'\n",
    "\n",
    "echo \"엔드포인트 구성 생성 성공.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# trigger일 경우 매번 다른 endpoint 생성시에 사용, 배치일경우 고정값 사용가능\n",
    "# endpoint name 검증 함수\n",
    "def sanitize_endpoint_name(name):\n",
    "    # 알파벳, 숫자, 하이픈만 허용하고 나머지는 제거\n",
    "    sanitized = re.sub(r'[^a-zA-Z0-9-]', '', name)\n",
    "    \n",
    "    # 이름이 하이픈으로 시작하거나 끝나면 제거\n",
    "    sanitized = sanitized.strip('-')\n",
    "    \n",
    "    # 이름이 50자를 초과하면 자르기\n",
    "    if len(sanitized) > 50:\n",
    "        sanitized = sanitized[:50]\n",
    "    \n",
    "    # 이름이 비어있거나 숫자로 시작하면 접두사 추가\n",
    "    # if not sanitized or sanitized[0].isdigit():\n",
    "        # sanitized = 'endpoint-' + sanitized\n",
    "    \n",
    "    sanitized = 'endpoint-' + sanitized\n",
    "    \n",
    "    return sanitized\n",
    "\n",
    "endpoint_name = sanitize_endpoint_name(prefix)\n",
    "# endpoint_name = \"endpoint-Upstage-Document-OCR\" #  배치일경우 고정값 사용가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating endpoint: 'endpoint-Upstage-Document-OCR'\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n",
      "Created endpoint: 'endpoint-Upstage-Document-OCR'\n"
     ]
    }
   ],
   "source": [
    "# 2-3. 모델 Endpoint 생성 ( vrid 이용하여 유일하게 생성)\n",
    "import upstage_ocr_endpoint\n",
    "\n",
    "endpoint_config_name = \"Upstage-Document-OCR-config\"\n",
    "endpoint_name = \"endpoint-Upstage-Document-OCR\"\n",
    "\n",
    "# 2-3. Endpoint 생성 및 배포\n",
    "upstage_ocr_endpoint.create_upstage_ocr_endpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    config_name=endpoint_config_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Athena 테이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created successfully\n"
     ]
    }
   ],
   "source": [
    "# 3-1. Glue Data Catalog에 데이터베이스 생성:\n",
    "glue_client = boto3.client('glue')\n",
    "database_name = \"video_analysis\"\n",
    "\n",
    "response = glue_client.create_database(\n",
    "    DatabaseInput={\n",
    "        'Name': database_name\n",
    "    }\n",
    ")\n",
    "print(\"Database created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully {'QueryExecutionId': 'f7aaefcf-4598-4741-a05d-52d5cfdebfbd', 'ResponseMetadata': {'RequestId': 'cc9f8aab-579e-4651-b59d-3db313e8c01c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 02 Sep 2024 06:42:35 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '59', 'connection': 'keep-alive', 'x-amzn-requestid': 'cc9f8aab-579e-4651-b59d-3db313e8c01c'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 3-2. Iceberg 테이블 생성:\n",
    "athena_client = boto3.client('athena')\n",
    "table_location = \"s3://gsshop-video-analysis-761482380245-ap-northeast-2/logs/tables/video_analysis_logs/\"\n",
    "athena_output_location = \"s3://gsshop-video-analysis-761482380245-ap-northeast-2/logs/athena_output/\"\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE video_analysis.video_analysis_logs (\n",
    "    vrid STRING,\n",
    "    current_time TIMESTAMP,\n",
    "    batch_execution_time DOUBLE,\n",
    "    status STRING,\n",
    "    error_message STRING,\n",
    "    partition_date DATE\n",
    ")\n",
    "PARTITIONED BY (partition_date)\n",
    "LOCATION '\"\"\"+table_location+\"\"\"'\n",
    "TBLPROPERTIES (\n",
    "    'table_type'='ICEBERG',\n",
    "    'format'='parquet',\n",
    "    'write_target_data_file_size_bytes'='536870912',\n",
    "    'optimize_rewrite_delete_file_threshold'='10'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString=query,\n",
    "    QueryExecutionContext={\n",
    "        'Database': database_name\n",
    "    },\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': athena_output_location\n",
    "    }\n",
    ")\n",
    "print(\"Table created successfully\",response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert operation SUCCEEDED\n",
      "[{'VarCharValue': 'video123'}, {'VarCharValue': '2023-06-01 12:00:00.000000'}, {'VarCharValue': '10.5'}, {'VarCharValue': 'SUCCESS'}, {'VarCharValue': ''}, {'VarCharValue': '2023-06-01'}]\n",
      "Update operation SUCCEEDED\n",
      "Delete operation SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "import athena_iceberg_functions\n",
    "\n",
    "# 사용 예시\n",
    "# Insert\n",
    "athena_iceberg_functions.insert_data('video123', '2023-06-01 12:00:00', 10.5, 'SUCCESS', '', '2023-06-01')\n",
    "\n",
    "# Read\n",
    "results = athena_iceberg_functions.read_data('2023-06-01')\n",
    "if results:\n",
    "    for row in results[1:]:  # Skip header\n",
    "        print(row['Data'])\n",
    "\n",
    "# # Update\n",
    "athena_iceberg_functions.update_data('video123', 'FAILED', '2023-06-01')\n",
    "\n",
    "# # Delete\n",
    "athena_iceberg_functions.delete_data('video123', '2023-06-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Batch Main 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 '_SUCCESS' files:\n",
      "images/staging/prd_01/vrid_00001/_SUCCESS Video Analysis Start!!\n",
      "Insert operation SUCCEEDED\n",
      "Total keys found: 62\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 3 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 5 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 6 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 52 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 53 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 54 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 55 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00001, 56 번째 이미지에 텍스트 없음\n",
      "Upstage Call Ended\n",
      "Insert operation SUCCEEDED\n",
      "images/staging/prd_01/vrid_00001/_SUCCESS Video Analysis End!!\n",
      "images/staging/prd_01/vrid_00002/_SUCCESS Video Analysis Start!!\n",
      "Insert operation SUCCEEDED\n",
      "Total keys found: 62\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 3 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 5 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 6 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 52 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 53 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 54 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 55 번째 이미지에 텍스트 없음\n",
      "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (503) from primary with message \"{\n",
      "  \"code\": 503,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"Prediction failed\"\n",
      "}\n",
      "\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-Upstage-Document-OCR in account 761482380245 for more information.\n",
      "vrid : vrid_00002, 56 번째 이미지에 텍스트 없음\n",
      "Upstage Call Ended\n",
      "Insert operation SUCCEEDED\n",
      "images/staging/prd_01/vrid_00002/_SUCCESS Video Analysis End!!\n",
      "images/staging/prd_01/vrid_00003/_SUCCESS Video Analysis Start!!\n",
      "Insert operation SUCCEEDED\n",
      "Total keys found: 3\n",
      "Upstage Call Ended\n",
      "Insert operation SUCCEEDED\n",
      "images/staging/prd_01/vrid_00003/_SUCCESS Video Analysis End!!\n",
      "GS SHOP Video Analysis Seccess!!\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import s3_functions\n",
    "import upstage_ocr_endpoint\n",
    "import bedrock_functions\n",
    "import athena_iceberg_functions\n",
    "from datetime import datetime\n",
    "\n",
    "# S3 버킷 이름과 경로 설정\n",
    "bucket = \"gsshop-video-analysis-761482380245-ap-northeast-2\"\n",
    "staging_prefix = \"images/staging/\"\n",
    "endpoint_name = \"endpoint-Upstage-Document-OCR\"\n",
    "\n",
    "def video_analyze(key):\n",
    "    # vrid 추출\n",
    "    vrid = key.split('/')[-2]\n",
    "    prefix = key.replace(\"_SUCCESS\",\"\")\n",
    "\n",
    "    # 시작 시간 기록\n",
    "    start_time = datetime.now()\n",
    "    current_time = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    partition_date = start_time.strftime('%Y-%m-%d')\n",
    "\n",
    "    # 시작 로그 추가\n",
    "    athena_iceberg_functions.insert_data(vrid, current_time, 0, 'STARTED', '', partition_date)\n",
    "    \n",
    "    try:\n",
    "        ### 2-4. s3에서 image 목록 불러오기\n",
    "        keys = s3_functions.list_s3_keys(bucket, prefix)\n",
    "        input_ocr_list = \"<input_ocr_list>\\n\"\n",
    "\n",
    "        ### 2-5 Upstage OCR 엔드포인트 호출\n",
    "        print(f\"Total keys found: {len(keys)}\")\n",
    "\n",
    "        i = 0\n",
    "        for s3_key in keys:\n",
    "            # print(\"s3_key ==> \" + s3_key)\n",
    "            if prefix != s3_key and f\"{prefix}_SUCCESS\" != s3_key:\n",
    "                image_data, content_type = s3_functions.download_from_s3(bucket, s3_key)\n",
    "                # print(\"image_data ==> \",image_data)\n",
    "                # print(\"content_type ==> \",content_type)\n",
    "                \n",
    "                image_stream = io.BytesIO(image_data)\n",
    "                # Image 객체 생성\n",
    "                img = Image.open(image_stream)\n",
    "\n",
    "                cropped_img = img.crop((990, 150, 1230, 640))\n",
    "                # cropped_img.save(\"test.jpg\", format='JPEG')\n",
    "\n",
    "                croped_byte_stream = io.BytesIO()\n",
    "                cropped_img.save(croped_byte_stream, format=\"JPEG\")  # 이미지 형식을 지정합니다. (예: PNG, JPEG 등)\n",
    "                croped_image_data = croped_byte_stream.getvalue()\n",
    "                \n",
    "                # 엔드포인트 호출 (S3에서 가져온 Content-Type 사용)\n",
    "                original_ocr_text = \"\"\n",
    "                try:\n",
    "                    response = upstage_ocr_endpoint.invoke_endpoint(endpoint_name, croped_image_data, content_type)\n",
    "                    original_ocr_text = response[\"text\"]\n",
    "                    \n",
    "                    ## OCR만 적용\n",
    "                    input_ocr_list += \"<frame>\\n\"\n",
    "                    input_ocr_list += \"  <frame_id>{}</frame_id>\\n\".format(i)\n",
    "                    input_ocr_list += \"  <original_ocr_text>{}</original_ocr_text>\\n\".format(original_ocr_text)\n",
    "                    input_ocr_list += \"</frame>\\n\"\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(f\"vrid : {vrid}, {i} 번째 이미지에 텍스트 없음\")\n",
    "                \n",
    "                i = i+1\n",
    "        input_ocr_list += \"</input_ocr_list>\"\n",
    "        print(f\"Upstage Call Ended\")\n",
    "\n",
    "        ### 2-6 bedrock 호출\n",
    "        result_json = bedrock_functions.get_final_result(input_ocr_list)\n",
    "\n",
    "        ### 2-7 Json 결과 s3에 저장\n",
    "        split_result = prefix.split(\"/\")\n",
    "        result_path_key = f\"results/{split_result[3]}.json\"\n",
    "        s3_functions.save_result_json(bucket, result_path_key, result_json)\n",
    "\n",
    "        ### 3-8 Json 결과 s3에 저장\n",
    "        source_folder = prefix\n",
    "        destination_folder = source_folder.replace(\"staging\",\"done\")\n",
    "        s3_functions.move_s3_folder(bucket, source_folder, destination_folder)\n",
    "    \n",
    "        # 성공 로그 추가\n",
    "        end_time = datetime.now()\n",
    "        execution_time = (end_time - start_time).total_seconds()\n",
    "        current_time = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        partition_date = end_time.strftime('%Y-%m-%d')\n",
    "        athena_iceberg_functions.insert_data(vrid, current_time, execution_time, 'SUCCESS', '', partition_date)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 실패 로그 추가\n",
    "        end_time = datetime.now()\n",
    "        execution_time = (end_time - start_time).total_seconds()\n",
    "        current_time = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        partition_date = end_time.strftime('%Y-%m-%d')\n",
    "        print(str(e))\n",
    "        athena_iceberg_functions.insert_data(vrid, current_time, execution_time, 'FAILED', str(e).replace(\"'\",\"`\"), partition_date)\n",
    "        raise e\n",
    "\n",
    "\n",
    "# 3-1. _SUCCESS 파일 목록 찾기\n",
    "success_files = s3_functions.find_success_files(bucket, staging_prefix)\n",
    "print(f\"Found {len(success_files)} '_SUCCESS' files:\")\n",
    "\n",
    "# 3-2. success_files이 존재 하면 프로세싱\n",
    "if len(success_files) > 0:\n",
    "      \n",
    "    # 최대 10개의 파일만 처리\n",
    "    for i, key in enumerate(success_files):\n",
    "        if i >= 10:\n",
    "            break        \n",
    "        print(f\"{key} Video Analysis Start!!\")\n",
    "        video_analyze(key)\n",
    "        print(f\"{key} Video Analysis End!!\")\n",
    "\n",
    "\n",
    "    print(f\"GS SHOP Video Analysis Seccess!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted endpoint: 'endpoint-Upstage-Document-OCR'\n"
     ]
    }
   ],
   "source": [
    "# 3-9 Upstage Endpoint 삭제\n",
    "upstage_ocr_endpoint.delete_upstage_ocr_endpoint(\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [참고] 테스트용 데이터 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## s3 초기화\n",
    "import s3_functions\n",
    "\n",
    "bucket = \"gsshop-video-analysis-761482380245-ap-northeast-2\"\n",
    " \n",
    "## 참고 폴더 원복\n",
    "### 2-9. 분석 후 폴더 이동\n",
    "def move_s3_folder(bucket, source_folder, destination_folder):\n",
    "\n",
    "    # 소스 폴더의 모든 객체 나열\n",
    "    response = s3.list_objects_v2(Bucket=bucket, Prefix=source_folder)\n",
    "\n",
    "    # 'Contents' 키가 응답에 있는지 확인\n",
    "    if 'Contents' not in response:\n",
    "        print(f\"No objects found in {source_folder}\")\n",
    "        return\n",
    "\n",
    "    for obj in response['Contents']:\n",
    "        old_key = obj['Key']\n",
    "        new_key = old_key.replace(source_folder, destination_folder, 1)\n",
    "\n",
    "        # 객체 복사\n",
    "        s3.copy_object(\n",
    "            Bucket=bucket,\n",
    "            CopySource={'Bucket': bucket, 'Key': old_key},\n",
    "            Key=new_key\n",
    "        )\n",
    "\n",
    "        # 원본 객체 삭제\n",
    "        s3.delete_object(Bucket=bucket, Key=old_key)\n",
    "\n",
    "        print(f\"Moved {old_key} to {new_key}\")\n",
    "\n",
    "staging_prefix = \"images/done/\"\n",
    "success_files = s3_functions.find_success_files(bucket, staging_prefix)\n",
    "\n",
    "for key in success_files:\n",
    "    # video_analyze(key)\n",
    "    prefix = key.replace(\"_SUCCESS\",\"\")\n",
    "    source_folder = prefix\n",
    "    destination_folder = source_folder.replace(\"done\",\"staging\")\n",
    "    s3_functions.move_s3_folder(bucket, source_folder, destination_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/vrid_00001.json\n",
      "results/vrid_00002.json\n",
      "results/vrid_00003.json\n"
     ]
    }
   ],
   "source": [
    "result_prefix = \"results/\"\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=result_prefix)\n",
    "\n",
    "success_files = []\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        key = obj['Key']\n",
    "        print(key)\n",
    "        s3.delete_object(Bucket=bucket, Key=key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
